# pgdb-queue

A lightweight Kafka-style queue built using a PostgreSQL database. Designed for simplicity, performance, and low cost â€” no need for Kafka, Redis, or additional infrastructure.

Ideal for startups and small apps that need reliable background task processing without operational overhead.

---

## ğŸš€ Features

- âœ… Kafka-like producer/consumer API
- âœ… Uses PostgreSQL for persistence
- âœ… Efficient LISTEN/NOTIFY-based message wake-up
- âœ… Zero-polling after queue is drained (saves DB read costs)
- âœ… Row-level locking using `FOR UPDATE SKIP LOCKED`
- âœ… Automatic retries for failed messages
- âœ… FIFO message ordering
- âœ… Minimal setup

---

## ğŸ“¦ Installation

```bash
npm install pgdb-queue
```

---

## ğŸ› ï¸ Setup

Before producing or consuming messages, initialize the queue:

```ts
import { initQueue } from "pgdb-queue";

await initQueue(
  "postgres://user:password@host:port/database",
  "schemaName.tableName"
);
```

This sets up the connection pool and ensures the `message_queue` table exists.

---

## ğŸ“¤ Producing Messages

```ts
import { produce } from "pgdb-queue";

await produce(
  "email-topic",
  JSON.stringify({
    to: "user@example.com",
    subject: "Welcome!",
  })
);
```

> The message must be a string. Use `JSON.stringify()` to send structured data.

**Parameters:**

- `topic`: `string`
- `message`: `string` (recommended: `JSON.stringify(object)`)

---

## ğŸ“¥ Consume a Single Message (Manual)

This gives you full control (useful in cron jobs or custom workers):

```ts
import { consume } from "pgdb-queue";

await consume("email-topic", async (msg, id) => {
  const data = JSON.parse(msg);
  console.log("Received:", data);
  // Your message handler logic
});
```

---

## ğŸ” `startConsumer`: Auto-Wake Continuous Consumer

Automatically listens for new messages and drains the queue efficiently:

```ts
import { startConsumer } from "pgdb-queue";

await startConsumer(
  "email-topic",
  async (msg, id) => {
    const data = JSON.parse(msg);
    console.log("Processing:", data);
    // Your message handler logic
  },
  {
    rateLimitMs: 10,
  }
);
```

### How it saves DB read costs

- Uses PostgreSQLâ€™s `LISTEN/NOTIFY` to be notified only when a new message is inserted.
- Drains messages until the queue is empty.
- Once the queue is empty, it stops polling â€” and resumes only when a new message is pushed.

> No `setInterval` polling = minimal read overhead.

Perfect for scalable background jobs with low or bursty volume.

---

## ğŸ—ƒï¸ Table Schema

The following table is automatically created (if missing):

```sql
CREATE TABLE IF NOT EXISTS schemaName.tableName (
  id SERIAL PRIMARY KEY,
  topic TEXT NOT NULL,
  message TEXT NOT NULL,
  status TEXT NOT NULL DEFAULT 'queued',
  retry_count INTEGER NOT NULL DEFAULT 0,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);
CREATE INDEX  IF NOT EXISTS idx_topic_status ON schemaName.tableName (topic, status);
```

> `message` is stored as `TEXT`.

---

## âš™ï¸ Roadmap

Planned features:

- â³ Delayed message delivery
- âš–ï¸ Per-topic concurrency limit
- ğŸ‘€ Visibility timeouts
- ğŸ’€ Dead-letter queue for persistent failures

---

## ğŸ§ª Example Use Cases

- ğŸ“§ Email sending
- ğŸ” Webhook dispatching
- ğŸ§¾ Background jobs (e.g. invoice generation)
- ğŸ”— Microservice coordination
- ğŸ“² Simple job queue for frontend apps (via API)

---

## ğŸ“„ License

MIT License  
Â© 2025 Shivaji Kumar
